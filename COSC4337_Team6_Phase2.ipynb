{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv(\"dataframe_NoIndex_YesHeader-_C.csv\")\n",
    "# print(cars.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countDigit(n):\n",
    "    count = 0\n",
    "    while n >= 1:\n",
    "        n //= 10\n",
    "        count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bacch\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\bacch\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\bacch\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\bacch\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "cars.loc[cars['currency'] == 0, 'price'] = cars['price']/3.74901\n",
    "cars.loc[cars['currency'] == 1, 'price'] = cars['price']/3.67264\n",
    "cars.loc[cars['currency'] == 2, 'price'] = cars['price']/3.63179\n",
    "cars.loc[cars['currency'] == 3, 'price'] = cars['price']/0.30191\n",
    "cars.loc[cars['currency'] == 4, 'price'] = cars['price']/0.38394\n",
    "cars.loc[cars['currency'] == 5, 'price'] = cars['price']/0.37489\n",
    "cars['price'] = cars['price'].astype(float)\n",
    "# print(cars.info())\n",
    "# print(cars['price'], cars['currency'])\n",
    "\n",
    "\n",
    "#Need to fix length, width, and height that are larger than 3 digits.\n",
    "for row in range(cars.shape[0]):\n",
    "    if countDigit(cars['Length'][row]) >= 3:\n",
    "        cars['Length'][row] = cars['Length'][row]/(10**(countDigit(cars['Length'][row])-1))\n",
    "    if countDigit(cars['Width'][row]) >= 3:\n",
    "        cars['Width'][row] = cars['Width'][row]/(10**(countDigit(cars['Width'][row])-1))\n",
    "    if countDigit(cars['Height'][row]) >= 3:\n",
    "        cars['Height'][row] = cars['Height'][row]/(10**(countDigit(cars['Height'][row])-1))\n",
    "    if countDigit(cars['Wheelbase'][row]) >= 3:\n",
    "        cars['Wheelbase'][row] = cars['Wheelbase'][row]/(10**(countDigit(cars['Wheelbase'][row])-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping duplicates\n",
    "from scipy import stats\n",
    "cars = cars.drop_duplicates(subset=['name', 'Country', 'price'], keep='first')\n",
    "cars = cars.drop(columns=['name'])\n",
    "\n",
    "#Removing outliers\n",
    "cars = cars[(np.abs(stats.zscore(cars)) < 3).all(axis=1)]\n",
    "# print(cars.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['Volume'] = cars['Length'] * cars['Width'] * cars['Height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = cars.drop(columns=['Length', 'Width', 'Height', 'Wheelbase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_col = cars\n",
    "X_col = X_col.drop(['price', 'Country', 'currency'], axis=1)\n",
    "X_scaled = scaler.fit_transform(X_col.values)\n",
    "# print(X_scaled)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns = ['Engine Capacity', 'Cylinders', 'Drive Type', 'Fuel Tank Capacity',\n",
    "            'Fuel Economy', 'Fuel Type', 'Horsepower', 'Torque', \n",
    "            'Transmission', 'Top Speed', 'Seating Capacity', 'Acceleration', \n",
    "            'Trunk Capacity','Volume'])\n",
    "\n",
    "\n",
    "#Important Predictors\n",
    "#Engine Capacity, Cylinders, Horsepower, Torque, Top Speed, Acceleration\n",
    "# X_scaled = X_scaled.drop(['Drive Type', 'Fuel Tank Capacity','Fuel Economy', 'Fuel Type','Transmission','Seating Capacity','Trunk Capacity','Volume'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create random training and testing sets\n",
    "from mlxtend.preprocessing import shuffle_arrays_unison\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=X_scaled[['Engine Capacity', 'Cylinders','Horsepower', 'Torque','Top Speed', 'Acceleration']]\n",
    "y=cars[['price']]\n",
    "y = np.sqrt(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.25,random_state=18)\n",
    "\n",
    "X_train_arr = X_train.values\n",
    "X_test_arr = X_test.values\n",
    "y_train_arr = y_train.values\n",
    "y_test_arr = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "R-squared =  0.850819714493983\n",
      "MAE =  24.88854276657499\n",
      "MSE =  1190.2838735285727\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "Linear_model = LinearRegression().fit(X_train, y_train)\n",
    "y_pred = Linear_model.predict(X_test)\n",
    "\n",
    "# print(Linear_model.coef_)\n",
    "\n",
    "print(\"Linear Regression\")\n",
    "print(\"R-squared = \", Linear_model.score(X_test, y_test))\n",
    "print(\"MAE = \",mean_absolute_error(y_test, y_pred))\n",
    "print(\"MSE = \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression: degree = 3\n",
      "R-squared =  0.8778335521024299\n",
      "MAE =  21.384771838540555\n",
      "MSE =  974.7451033862058\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score\n",
    "poly = PolynomialFeatures(degree = 3)\n",
    "X_poly = poly.fit_transform(X_train)\n",
    "\n",
    "poly.fit(X_poly, y_train)\n",
    "poly_model = LinearRegression().fit(X_poly, y_train)\n",
    "X_poly_test = poly.fit_transform(X_test)\n",
    "\n",
    "y_pred = poly_model.predict(X_poly_test)\n",
    "\n",
    "print(\"Polynomial Regression: degree = 3\")\n",
    "print(\"R-squared = \", r2_score(y_test, y_pred))\n",
    "print(\"MAE = \",mean_absolute_error(y_test, y_pred))\n",
    "print(\"MSE = \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 84 is different from 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-e522a92ead76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_poly_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3.01\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoly_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_poly_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \"\"\"\n\u001b[1;32m--> 238\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[1;32m--> 222\u001b[1;33m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 84 is different from 4)"
     ]
    }
   ],
   "source": [
    "X_poly_test = poly.fit_transform(np.array([[3.01], [0], [0], [0], [0], [0]]))\n",
    "\n",
    "y_pred = poly_model.predict(X_poly_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Show models for each predictor in linear just to give an idea. \n",
    "# for p in ['Engine Capacity', 'Cylinders','Horsepower', 'Torque','Top Speed', 'Acceleration']:\n",
    "# #     Xp = X_train[p].to_numpy().reshape(-1, 1)\n",
    "# #     Xp_test = X_test[p].to_numpy().reshape(-1, 1)\n",
    "# #     model = LinearRegression().fit(Xp, y_train)\n",
    "# #     y_pred = Linear_model.predict(Xp_test)\n",
    "    \n",
    "#     fig = plt.figure(figsize=(8,5))\n",
    "#     sns.regplot(x = cars[p], y = cars['price'])\n",
    "# #     x = np.linspace(min(cars[p]), max(cars[p]), 100)\n",
    "# #     y = model.intercept_ + model.coef_ * x\n",
    "# #     y = y.reshape(-1,1)\n",
    "# #     plt.plot(x, y, '-r', label='Linear Model')\n",
    "#     plt.xlabel(p, size=18)\n",
    "#     plt.ylabel('Price', size=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show models for each predictor in polynomial\n",
    "# for p in ['Engine Capacity', 'Cylinders','Horsepower', 'Torque','Top Speed', 'Acceleration']:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Everything below was for Phase 2. Just uncomment and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from yellowbrick.regressor import ResidualsPlot\n",
    "\n",
    "# visualizer = ResidualsPlot(Linear_model, hist=False)\n",
    "\n",
    "# visualizer.fit(X_train, y_train)  \n",
    "# visualizer.score(X_test, y_test)  \n",
    "# visualizer.show()\n",
    "\n",
    "\n",
    "\n",
    "# # y_pred = pd.DataFrame(y_pred, columns = ['price'])\n",
    "# residuals = y_test - y_pred\n",
    "# sns.histplot(residuals, kde=True)\n",
    "# plt.title(\"Residual Count\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(y_test, y_pred)\n",
    "# plt.title('Actual vs Predicted Values')\n",
    "# plt.xlabel('Actual')\n",
    "# plt.ylabel('Predicted')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Polynomial Regression\n",
    "# #Create a model for each important predictor\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# from sklearn.metrics import r2_score\n",
    "# poly = PolynomialFeatures(degree = 2)\n",
    "# X_poly = poly.fit_transform(X_train)\n",
    "\n",
    "# # print(X_poly.shape)\n",
    "\n",
    "# poly.fit(X_poly, y_train)\n",
    "# poly_model = LinearRegression().fit(X_poly, y_train)\n",
    "# X_poly_test = poly.fit_transform(X_test)\n",
    "\n",
    "# y_pred = poly_model.predict(X_poly_test)\n",
    "\n",
    "# print(\"Polynomial Regression: degree = 2\")\n",
    "# print(\"R-squared = \", r2_score(y_test, y_pred))\n",
    "# print(\"MAE = \",mean_absolute_error(y_test, y_pred))\n",
    "# print(\"MSE = \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizer = ResidualsPlot(poly_model, hist=False)\n",
    "\n",
    "# visualizer.fit(X_poly, y_train)  \n",
    "# visualizer.score(X_poly_test, y_test)  \n",
    "# visualizer.show()\n",
    "\n",
    "# # y_pred = pd.DataFrame(y_pred, columns = ['price'])\n",
    "# residuals = y_test - y_pred\n",
    "# sns.histplot(residuals, kde=True)\n",
    "# plt.title(\"Residual Count\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(y_test, y_pred)\n",
    "# plt.title('Actual vs Predicted Values')\n",
    "# plt.xlabel('Actual')\n",
    "# plt.ylabel('Predicted')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poly = PolynomialFeatures(degree = 3)\n",
    "# X_poly = poly.fit_transform(X_train)\n",
    "\n",
    "# # print(X_poly.shape)\n",
    "\n",
    "# poly.fit(X_poly, y_train)\n",
    "# poly_model = LinearRegression().fit(X_poly, y_train)\n",
    "# X_poly_test = poly.fit_transform(X_test)\n",
    "\n",
    "# y_pred = poly_model.predict(X_poly_test)\n",
    "\n",
    "# print(\"Polynomial Regression: degree = 3\")\n",
    "# print(\"R-squared = \", r2_score(y_test, y_pred))\n",
    "# print(\"MAE = \",mean_absolute_error(y_test, y_pred))\n",
    "# print(\"MSE = \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizer = ResidualsPlot(poly_model, hist=False)\n",
    "\n",
    "# visualizer.fit(X_poly, y_train)  \n",
    "# visualizer.score(X_poly_test, y_test)  \n",
    "# visualizer.show()\n",
    "\n",
    "\n",
    "# # y_pred = pd.DataFrame(y_pred, columns = ['price'])\n",
    "# residuals = y_test - y_pred\n",
    "# sns.histplot(residuals, kde=True)\n",
    "# plt.title(\"Residual Count\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(y_test, y_pred)\n",
    "# plt.title('Actual vs Predicted Values')\n",
    "# plt.xlabel('Actual')\n",
    "# plt.ylabel('Predicted')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import Ridge\n",
    "# from sklearn.linear_model import RidgeCV\n",
    "# from sklearn.model_selection import RepeatedKFold\n",
    "# from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "# from loguniform import LogUniform\n",
    "\n",
    "# model = Ridge()\n",
    "# # cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=18)\n",
    "\n",
    "# space = dict()\n",
    "# space['solver'] = ['svd', 'cholesky', 'lsqr', 'sag']\n",
    "# space['alpha'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 5, 10, 100]\n",
    "# space['fit_intercept'] = [True, False]\n",
    "# space['normalize'] = [True, False]\n",
    "\n",
    "# search = GridSearchCV(model, space, n_jobs=-1, cv=5)\n",
    "\n",
    "# result = search.fit(X_train, y_train)\n",
    "\n",
    "# print('Best Score: %s' % result.best_score_)\n",
    "# print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge = Ridge(alpha = 1, solver='sag')\n",
    "# ridge.fit(X_train, y_train)\n",
    "# y_pred = ridge.predict(X_test)\n",
    "\n",
    "# print(\"Ridge Regression: alpha = 1\")\n",
    "# print(\"R-squared = \", r2_score(y_test, y_pred))\n",
    "# print(\"MAE = \",mean_absolute_error(y_test, y_pred))\n",
    "# print(\"MSE = \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizer = ResidualsPlot(ridge, hist=False)\n",
    "\n",
    "# visualizer.fit(X_train, y_train)  \n",
    "# visualizer.score(X_test, y_test)  \n",
    "# visualizer.show()\n",
    "\n",
    "\n",
    "# # y_pred = pd.DataFrame(y_pred, columns = ['price'])\n",
    "# residuals = y_test - y_pred\n",
    "# sns.histplot(residuals, kde=True)\n",
    "# plt.title(\"Residual Count\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(y_test, y_pred)\n",
    "# plt.title('Actual vs Predicted Values')\n",
    "# plt.xlabel('Actual')\n",
    "# plt.ylabel('Predicted')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Ridge Regression\n",
    "\n",
    "# ridge = Ridge(alpha = 5, solver='sag')\n",
    "# ridge.fit(X_train, y_train)\n",
    "# y_pred = ridge.predict(X_test)\n",
    "\n",
    "# print(\"Ridge Regression: alpha = 5\")\n",
    "# print(\"R-squared = \", r2_score(y_test, y_pred))\n",
    "# print(\"MAE = \",mean_absolute_error(y_test, y_pred))\n",
    "# print(\"MSE = \", mean_squared_error(y_test, y_pred))\n",
    "# # print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizer = ResidualsPlot(ridge, hist=False)\n",
    "\n",
    "# visualizer.fit(X_train, y_train)  \n",
    "# visualizer.score(X_test, y_test)  \n",
    "# visualizer.show()\n",
    "\n",
    "# # y_pred = pd.DataFrame(y_pred, columns = ['price'])\n",
    "\n",
    "# residuals = y_test - y_pred\n",
    "# sns.histplot(residuals, kde=True)\n",
    "# plt.title(\"Residual Count\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(y_test, y_pred)\n",
    "# plt.title('Actual vs Predicted Values')\n",
    "# plt.xlabel('Actual')\n",
    "# plt.ylabel('Predicted')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge = Ridge(alpha = .001, solver='lsqr', normalize = True)\n",
    "# ridge.fit(X_train, y_train)\n",
    "# y_pred = ridge.predict(X_test)\n",
    "\n",
    "# print(\"Ridge Regression: alpha = .001\")\n",
    "# print(\"R-squared = \", r2_score(y_test, y_pred))\n",
    "# print(\"MAE = \",mean_absolute_error(y_test, y_pred))\n",
    "# print(\"MSE = \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizer = ResidualsPlot(ridge, hist=False)\n",
    "\n",
    "# visualizer.fit(X_train, y_train)  \n",
    "# visualizer.score(X_test, y_test)  \n",
    "# visualizer.show()\n",
    "# # print(y_test)\n",
    "# # print(y_pred)\n",
    "\n",
    "# # print(type(y_test))\n",
    "# # print(type(y_pred))\n",
    "\n",
    "# # y_pred = pd.DataFrame(y_pred, columns = ['price'])\n",
    "\n",
    "# residuals = y_test - y_pred\n",
    "# # print(residuals)\n",
    "# sns.histplot(residuals, kde=True)\n",
    "# plt.title(\"Residual Count\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(y_test, y_pred)\n",
    "# plt.title('Actual vs Predicted Values')\n",
    "# plt.xlabel('Actual')\n",
    "# plt.ylabel('Predicted')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.linear_model import Lasso\n",
    "# model = Lasso()\n",
    "# # cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=18)\n",
    "\n",
    "# space = dict()\n",
    "# # space['solver'] = ['svd', 'cholesky', 'lsqr', 'sag']\n",
    "# space['alpha'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 5, 10, 100]\n",
    "# space['max_iter'] = [100, 1000, 10000]\n",
    "# space['fit_intercept'] = [True, False]\n",
    "# space['normalize'] = [True, False]\n",
    "\n",
    "# search = GridSearchCV(model, space, n_jobs=-1, cv=5)\n",
    "\n",
    "# result = search.fit(X_train, y_train)\n",
    "\n",
    "# print('Best Score: %s' % result.best_score_)\n",
    "# print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso = Lasso(alpha = 1, max_iter=10000, normalize = False)\n",
    "# # lasso.fit(X_train, y_train)\n",
    "\n",
    "# # lasso.set_params(alpha=lassocv.alpha_)\n",
    "# lasso.fit(X_train, y_train)\n",
    "# # print(lasso.coef_)\n",
    "# y_pred = lasso.predict(X_test)\n",
    "# print(\"Lasso Regression: alpha = 1\")\n",
    "# print(\"R-squared = \", r2_score(y_test, y_pred))\n",
    "# print(\"MAE = \",mean_absolute_error(y_test, y_pred))\n",
    "# print(\"MSE = \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = y_pred.reshape(904,1)\n",
    "# residuals = y_test-y_pred\n",
    "\n",
    "# plt.scatter(y_pred, residuals, color='blue')\n",
    "# # plt.plot(0,0, color='black')\n",
    "# plt.title('Residuals for Lasso')\n",
    "# plt.xlabel('Predicted Value')\n",
    "# plt.ylabel('Residuals')\n",
    "# plt.show()\n",
    "\n",
    "# sns.histplot(residuals, kde=True)\n",
    "# plt.title(\"Residual Count\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(y_test, y_pred)\n",
    "# plt.title('Actual vs Predicted Values')\n",
    "# plt.xlabel('Actual')\n",
    "# plt.ylabel('Predicted')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Lasso Regression\n",
    "# lasso = Lasso(alpha = .001, max_iter=1000, normalize = False)\n",
    "\n",
    "# lasso.fit(X_train, y_train)\n",
    "# # print(lasso.coef_)\n",
    "# y_pred = lasso.predict(X_test)\n",
    "# print(\"Lasso Regression: alpha = .001\")\n",
    "# print(\"R-squared = \", r2_score(y_test, y_pred))\n",
    "# print(\"MAE = \",mean_absolute_error(y_test, y_pred))\n",
    "# print(\"MSE = \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # y_pred = pd.DataFrame(y_pred, columns = ['price'])\n",
    "# y_pred = y_pred.reshape(904,1)\n",
    "# residuals = y_test - y_pred\n",
    "# # sns.histplot(residuals, kde=True)\n",
    "\n",
    "# plt.scatter(y_pred, residuals, color='blue')\n",
    "# plt.title('Residuals for Lasso')\n",
    "# plt.xlabel('Predicted Value')\n",
    "# plt.ylabel('Residuals')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# sns.histplot(residuals, kde=True)\n",
    "# plt.title(\"Residual Count\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(y_test, y_pred)\n",
    "# plt.title('Actual vs Predicted Values')\n",
    "# plt.xlabel('Actual')\n",
    "# plt.ylabel('Predicted')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso = Lasso(alpha = 5, max_iter=1000, normalize = False)\n",
    "\n",
    "# lasso.fit(X_train, y_train)\n",
    "# y_pred = lasso.predict(X_test)\n",
    "# print(\"Lasso Regression: alpha = 5\")\n",
    "# print(\"R-squared = \", r2_score(y_test, y_pred))\n",
    "# print(\"MAE = \",mean_absolute_error(y_test, y_pred))\n",
    "# print(\"MSE = \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # y_pred = pd.DataFrame(y_pred, columns = ['price'])\n",
    "# y_pred = y_pred.reshape(904,1)\n",
    "# residuals = y_test - y_pred\n",
    "\n",
    "\n",
    "# plt.scatter(y_pred, residuals, color='blue')\n",
    "# plt.title('Residuals for Lasso')\n",
    "# plt.xlabel('Predicted Value')\n",
    "# plt.ylabel('Residuals')\n",
    "# plt.show()\n",
    "\n",
    "# sns.histplot(residuals, kde=True)\n",
    "# plt.title(\"Residual Count\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(y_test, y_pred)\n",
    "# plt.title('Actual vs Predicted Values')\n",
    "# plt.xlabel('Actual')\n",
    "# plt.ylabel('Predicted')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
